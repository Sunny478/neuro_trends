{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!cp ../input/rapids/rapids.0.13.0 /opt/conda/envs/rapids.tar.gz\n",
    "!cd /opt/conda/envs/ && tar -xzvf rapids.tar.gz > /dev/null\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib/python3.6/site-packages\"] + sys.path\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib/python3.6\"] + sys.path\n",
    "sys.path = [\"/opt/conda/envs/rapids/lib\"] + sys.path\n",
    "!cp /opt/conda/envs/rapids/lib/libxgboost.so /opt/conda/lib/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import cupy as cp\n",
    "import cudf\n",
    "import cuml \n",
    "from cuml.ensemble import RandomForestRegressor\n",
    "\n",
    "\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn \n",
    "\n",
    "def metric(y_true, y_pred):\n",
    "    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0)/np.sum(y_true, axis=0))\n",
    "\n",
    "!mkdir preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "fnc = pd.read_csv('../input/trends-assessment-prediction/fnc.csv')\n",
    "loading = pd.read_csv('../input/trends-assessment-prediction/loading.csv')\n",
    "sample = pd.read_csv('../input/trends-assessment-prediction/sample_submission.csv')\n",
    "train_scores = pd.read_csv('../input/trends-assessment-prediction/train_scores.csv')\n",
    "\n",
    "\n",
    "fnc_features, loading_features = list(fnc.columns[1:]), list(loading.columns[1:])\n",
    "target_cols = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2', ]\n",
    "loading = loading.drop(['IC_20'], axis=1)\n",
    "loading_features.remove('IC_20')\n",
    "\n",
    "df = fnc.merge(loading, on=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "NUM_FOLDS = 7\n",
    "FNC_SCALE = 1/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores[\"is_train\"] = True\n",
    "df = df.merge(train_scores, on=\"Id\", how=\"left\")\n",
    "\n",
    "test_df = df[df[\"is_train\"] != True].copy()\n",
    "df = df[df[\"is_train\"] == True].copy()\n",
    "\n",
    "df[fnc_features] *= FNC_SCALE\n",
    "test_df[fnc_features] *= FNC_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age += np.random.uniform(0, 1.0, df.shape[0])\n",
    "df.domain1_var1 += np.random.uniform(0, 1.0, df.shape[0])\n",
    "df.domain1_var2 += np.random.uniform(0, 1.0, df.shape[0])\n",
    "df.domain2_var1 += np.random.uniform(0, 1.0, df.shape[0])\n",
    "df.domain2_var2 += np.random.uniform(0, 1.0, df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = fnc_features + loading_features + target_cols\n",
    "df[features] = df[features].astype(np.float32)\n",
    "test_df[features] = test_df[features].astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cudf.from_pandas(df)\n",
    "test_df = cudf.from_pandas(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    \n",
    "{   'rf_max_depth' : 10,                     #params of age\n",
    "    'rf_n_estimators': 100 }, \n",
    "    \n",
    "{   'rf_max_depth' : 10,                     #params of d1v1\n",
    "    'rf_n_estimators': 100 }, \n",
    "\n",
    "{   'rf_max_depth' : 10,                     #params of d1v2\n",
    "    'rf_n_estimators': 250 }, \n",
    "    \n",
    "{   'rf_max_depth' : 10,                     #params of d2v1\n",
    "    'rf_n_estimators': 150 }, \n",
    "    \n",
    "{   'rf_max_depth' : 10,                     #params of d2v2\n",
    "    'rf_n_estimators': 250 }\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, target in enumerate(target_cols):\n",
    "    \n",
    "    print('========={}.{}========='.format(i+1, target))\n",
    "    \n",
    "    rf = RandomForestRegressor(n_estimators=params[i]['rf_n_estimators'], max_depth=params[i]['rf_max_depth'])\n",
    "    models = [ rf ]\n",
    "    \n",
    "    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n",
    "    features = loading_features + fnc_features \n",
    "    \n",
    "    for model in models:\n",
    "    \n",
    "        y_oof = np.zeros(df.shape[0])\n",
    "        y_test = np.zeros((test_df.shape[0], NUM_FOLDS))\n",
    "\n",
    "        for f, (train_ind, val_ind) in enumerate(kf.split(df, df)):\n",
    "            train_df, val_df = df.iloc[train_ind], df.iloc[val_ind]\n",
    "            train_df = train_df[train_df[target].notnull()]\n",
    "            \n",
    "            model.fit(train_df[features], train_df[target])\n",
    "\n",
    "            y_oof[val_ind] = model.predict(val_df[features])\n",
    "            y_test[:, f] = model.predict(test_df[features])\n",
    "\n",
    "        df['pred_{}_{}'.format(str(model).split('(')[0],target)] = y_oof\n",
    "        test_df['{}_{}'.format(str(model).split('(')[0],target)] = y_test.mean(axis=1)\n",
    "\n",
    "        score = metric(df[df[target].notnull()][target].values, df[df[target].notnull()]['pred_{}_{}'.format(str(model).split('(')[0],target)].values)\n",
    "        print(str(model).split('(')[0], np.round(score, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    \n",
    "    meta_df = cudf.DataFrame(columns = ['Id'] + target_cols)\n",
    "    meta_df.Id = df.Id\n",
    "    for col in target_cols:\n",
    "        meta_df[col] = df['pred_{}_{}'.format(str(model).split('(')[0],col)]\n",
    "        \n",
    "    meta_df.to_csv('{}.csv'.format(str(model).split('(')[0]), index=False)\n",
    "    \n",
    "    meta_test_df = cudf.DataFrame(columns = ['Id'] + target_cols)\n",
    "    meta_test_df.Id = test_df.Id\n",
    "    for col in target_cols:\n",
    "        meta_test_df[col] = test_df['{}_{}'.format(str(model).split('(')[0],col)]\n",
    "        \n",
    "    meta_test_df.to_csv('test_{}.csv'.format(str(model).split('(')[0]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
