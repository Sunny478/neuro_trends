{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "def ignore_warn(*args, **kwargs):\n",
    "    pass\n",
    "warnings.warn = ignore_warn \n",
    "\n",
    "def metric(y_true, y_pred):\n",
    "    return np.mean(np.sum(np.abs(y_true - y_pred), axis=0)/np.sum(y_true, axis=0))\n",
    "\n",
    "!mkdir preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "fnc = pd.read_csv('../input/trends-assessment-prediction/fnc.csv')\n",
    "loading = pd.read_csv('../input/trends-assessment-prediction/loading.csv')\n",
    "sample = pd.read_csv('../input/trends-assessment-prediction/sample_submission.csv')\n",
    "train_scores = pd.read_csv('../input/trends-assessment-prediction/train_scores.csv')\n",
    "\n",
    "fnc_features, loading_features = list(fnc.columns[1:]), list(loading.columns[1:])\n",
    "target_cols = ['age', 'domain1_var1', 'domain1_var2', 'domain2_var1', 'domain2_var2', ]\n",
    "loading = loading.drop(['IC_20'], axis=1)\n",
    "loading_features.remove('IC_20')\n",
    "\n",
    "df = fnc.merge(loading, on=\"Id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "NUM_FOLDS = 7\n",
    "FNC_SCALE = 1/500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores[\"is_train\"] = True\n",
    "df = df.merge(train_scores, on=\"Id\", how=\"left\")\n",
    "\n",
    "test_df = df[df[\"is_train\"] != True].copy()\n",
    "df = df[df[\"is_train\"] == True].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[fnc_features] *= FNC_SCALE\n",
    "test_df[fnc_features] *= FNC_SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.age += np.random.uniform(0, 1.0, df.shape[0])\n",
    "df.domain1_var1 += np.random.uniform(0, 1.0, df.shape[0])\n",
    "df.domain1_var2 += np.random.uniform(0, 1.0, df.shape[0])\n",
    "df.domain2_var1 += np.random.uniform(0, 1.0, df.shape[0])\n",
    "df.domain2_var2 += np.random.uniform(0, 1.0, df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\n",
    "    \n",
    "{   'xgb_max_depth' : 2,                     #params of age\n",
    "    'xgb_lr' : 0.25,\n",
    "    'xgb_n_estimators': 100,\n",
    "    'cat_max_depth' : 4 ,                     \n",
    "    'cat_lr' : 0.05,\n",
    "    'cat_iterations': 2000 ,\n",
    "    'lgb_max_depth' : 10,                     \n",
    "    'lgb_lr' : 0.1,\n",
    "    'lgb_n_estimators': 500 },\n",
    "\n",
    "{   'xgb_max_depth' : 2,                     #params of d1v1\n",
    "    'xgb_lr' : 0.25,\n",
    "    'xgb_n_estimators': 150,\n",
    "    'cat_max_depth' : 2,                     \n",
    "    'cat_lr' : 0.03,\n",
    "    'cat_iterations': 1500,\n",
    "    'lgb_max_depth' : 2,                     \n",
    "    'lgb_lr' : 0.1,\n",
    "    'lgb_n_estimators':100  },\n",
    "\n",
    "{   'xgb_max_depth' : 2,                     #params of d1v2\n",
    "    'xgb_lr' : 0.35,\n",
    "    'xgb_n_estimators': 10,\n",
    "    'cat_max_depth' : 2,                     \n",
    "    'cat_lr' : 0.006,\n",
    "    'cat_iterations': 1500,\n",
    "    'lgb_max_depth' : 2,                     \n",
    "    'lgb_lr' : 0.01,\n",
    "    'lgb_n_estimators':  200},\n",
    "\n",
    "{   'xgb_max_depth' : 2,                     #params of d2v1\n",
    "    'xgb_lr' : 0.05,\n",
    "    'xgb_n_estimators': 150,\n",
    "    'cat_max_depth' : 2,                     \n",
    "    'cat_lr' : 0.02,\n",
    "    'cat_iterations': 1000,\n",
    "    'lgb_max_depth' : 2,                     \n",
    "    'lgb_lr' : 0.075,\n",
    "    'lgb_n_estimators': 100 },\n",
    "\n",
    "{   'xgb_max_depth' : 2,                     #params of d2v2\n",
    "    'xgb_lr' : 0.4,\n",
    "    'xgb_n_estimators': 10,\n",
    "    'cat_max_depth' : 2,                     \n",
    "    'cat_lr' : 0.02,\n",
    "    'cat_iterations': 500,\n",
    "    'lgb_max_depth' : 2,                     \n",
    "    'lgb_lr' : 0.025,\n",
    "    'lgb_n_estimators': 200 },\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for i, target in enumerate(target_cols):\n",
    "    \n",
    "    print('========={}.{}========='.format(i+1, target))\n",
    "    \n",
    "    xgb = XGBRegressor(max_depth=params[i]['xgb_max_depth'], learning_rate=params[i]['xgb_lr'], n_estimators=params[i]['xgb_n_estimators'], tree_method= 'gpu_hist', verbose=0)\n",
    "    cat = CatBoostRegressor(max_depth=params[i]['cat_max_depth'], learning_rate=params[i]['cat_lr'], iterations=params[i]['cat_iterations'], task_type = 'GPU', verbose=0)\n",
    "    lgb = LGBMRegressor(max_depth=params[i]['lgb_max_depth'], learning_rate=params[i]['lgb_lr'], n_estimators=params[i]['lgb_n_estimators'], device='gpu', gpu_platform_id= 0, gpu_device_id=0, verbose=0 )\n",
    "    \n",
    "    models = [ xgb, cat, lgb ]\n",
    "    \n",
    "    kf = KFold(n_splits=NUM_FOLDS, shuffle=True, random_state=SEED)\n",
    "    features = loading_features + fnc_features \n",
    "    \n",
    "    for model in models:\n",
    "    \n",
    "        y_oof = np.zeros(df.shape[0])\n",
    "        y_test = np.zeros((test_df.shape[0], NUM_FOLDS))\n",
    "\n",
    "        for f, (train_ind, val_ind) in enumerate(kf.split(df, df)):\n",
    "            train_df, val_df = df.iloc[train_ind], df.iloc[val_ind]\n",
    "            train_df = train_df[train_df[target].notnull()]\n",
    "            \n",
    "            model.fit(train_df[features].values, train_df[target].values)\n",
    "\n",
    "            y_oof[val_ind] = model.predict(val_df[features].values)\n",
    "            y_test[:, f] = model.predict(test_df[features].values)\n",
    "\n",
    "        df['pred_{}_{}'.format(str(model).split('(')[0],target)] = y_oof\n",
    "        test_df['{}_{}'.format(str(model).split('(')[0],target)] = y_test.mean(axis=1)\n",
    "\n",
    "        score = metric(df[df[target].notnull()][target].values, df[df[target].notnull()]['pred_{}_{}'.format(str(model).split('(')[0],target)].values)\n",
    "        print(str(model).split('(')[0], np.round(score, 5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_changed_df = [x for x in df.columns if x.startswith('pred_<') ]\n",
    "new_names_df = [x.split('<')[0]+'cat'+x.split('>')[-1] for x in df.columns if x.startswith('pred_<') ]\n",
    "to_be_changed_test = [x for x in test_df.columns if x.startswith('<') ]\n",
    "new_names_test = ['cat'+x.split('>')[-1] for x in test_df.columns if x.startswith('<') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns=dict(zip(to_be_changed_df, new_names_df)), inplace=True)\n",
    "test_df.rename(columns=dict(zip(to_be_changed_test, new_names_test)), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = ['XGBRegressor', 'cat', 'LGBMRegressor' ]\n",
    "\n",
    "for model in models:\n",
    "    \n",
    "    meta_df = pd.DataFrame(columns = ['Id'] + target_cols)\n",
    "    meta_df.Id = df.Id\n",
    "    for col in target_cols:\n",
    "        meta_df[col] = df['pred_{}_{}'.format(str(model).split('(')[0],col)]\n",
    "        \n",
    "    meta_df.to_csv('preds/{}.csv'.format(str(model).split('(')[0]), index=False)\n",
    "    \n",
    "    meta_test_df = pd.DataFrame(columns = ['Id'] + target_cols)\n",
    "    meta_test_df.Id = test_df.Id\n",
    "    for col in target_cols:\n",
    "        meta_test_df[col] = test_df['{}_{}'.format(str(model).split('(')[0],col)]\n",
    "        \n",
    "    meta_test_df.to_csv('preds/test_{}.csv'.format(str(model).split('(')[0]), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
